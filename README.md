# Data Migration API

This is a Proof of Concept (PoC) API built with FastAPI to support a large-scale data migration pipeline. It enables loading historical data from CSV files, managing data via REST endpoints, and backing up or restoring table contents in AVRO format.

---

## ğŸš€ Features

- Load historic data from CSV files into a SQL database
- Receive and validate new data via REST endpoints
- Single and batch transaction support (1 to 1000 rows)
- AVRO export of each table's data
- Table restoration from AVRO backups
- Docker-ready and deployable in isolated environments

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/                          # Logging and configuration
â”‚   â”‚   â””â”€â”€ logger.py                  # Logger configuration
â”‚   â”œâ”€â”€ exporters/                     # Backup and restore logic (AVRO)
â”‚   â”‚   â”œâ”€â”€ avro_utils.py              # Utility functions for AVRO read/write
â”‚   â”‚   â”œâ”€â”€ backup_departments.py      # AVRO backup logic for departments
â”‚   â”‚   â”œâ”€â”€ backup_hired_employees.py  # AVRO backup logic for hired employees
â”‚   â”‚   â””â”€â”€ backup_jobs.py             # AVRO backup logic for jobs
â”‚   â”œâ”€â”€ loaders/                       # Loaders for historical data
â”‚   â”‚   â”œâ”€â”€ base_loader.py             # Common logic for all data loaders
â”‚   â”‚   â”œâ”€â”€ department_loader.py       # Loader for departments.csv
â”‚   â”‚   â”œâ”€â”€ hire_employee_loader.py    # Loader for hired_employees.csv
â”‚   â”‚   â””â”€â”€ job_loader.py              # Loader for jobs.csv
â”‚   â”œâ”€â”€ routers/                       # FastAPI endpoints
|   â”œâ”€â”€ backup_data.py                 # Backup dispatcher for all tables
â”‚   â”œâ”€â”€ database.py                    # DB engine/session creation
|   â”œâ”€â”€ load_data.py                   # Load all CSVs into the database
â”‚   â”œâ”€â”€ models.py                      # ORM models
â”‚   â”œâ”€â”€ restore_data.py                # Restore dispatcher for all tables
â”‚   â””â”€â”€ schemas.py                     # Pydantic schemas
â”œâ”€â”€ data/                              # Historical CSV files
â”œâ”€â”€ backups/                           # Generated AVRO backup files
â”œâ”€â”€ utils/                             # Utility scripts
â”‚   â””â”€â”€ clean_data.py                  # Script to delete all data from DB
â”œâ”€â”€ Dockerfile                         # Docker image definition
â”œâ”€â”€ main.py                            # FastAPI entry point
â”œâ”€â”€ Makefile                           # Automation of common tasks
â”œâ”€â”€ README.md                          # Project documentation
â””â”€â”€ requirements.txt                   # Python dependencies

```

---

## âš™ï¸ Setup Instructions

### ğŸ“¦ 1. Clone the Repository

```bash
git clone git@github.com:angie1590/data_migration_api.git
cd data_migration_api
```

### ğŸ 2. Create Virtual Environment (Optional if not using Docker)
> En estos casos es necesario tener instalado python 3.10 o superior. AdemÃ¡s instalar la librerÃ­a lmaz (brew install xy)
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### ğŸ”§ Installing `make` on the Local Environment (Windows/Mac) (Must)
> Required to run `Makefile` commands
```bash
# Windows (con Chocolatey)
choco install make

# Mac
brew install make
```

---

## ğŸ³ Docker Deployment (Recommended)

>The system is fully dockerized and ready for deployment.

### ğŸ”§ 1. Build the Docker Image

```bash
make docker-build
```

### â–¶ï¸ 2. Run the API Container

```bash
make docker-run
```

### â–¶ï¸ 3. Open a container shell

```bash
make docker-run-shell
```

Now the API is available at: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ“‚ Load Historical Data

### â• From the Host:

```bash
make load-historical-data
```

### â• From Docker:

```bash
make docker-load-historical
```

---

## ğŸ’¾ Backup & Restore (AVRO Format)
> You can backup and restore the three tables: departments, jobs, hired_employees. It is possible to do those process for all of them.

### ğŸ” Backup from Host:

```bash
make backup TABLE=departments
```

### ğŸ” Backup from Docker:

```bash
make docker-backup departments
```

### ğŸ” Backup all tables from Docker:

```bash
make docker-backup-all
```

### â™»ï¸ Restore from Host:

```bash
make restore TABLE=departments
```

### â™»ï¸ Restore from Docker:

```bash
make docker-restore TABLE=departments
```

### â™»ï¸ Restore all tables from Docker:

```bash
make docker-restore-all
```

---

## ğŸ§ª Clean the Database

### Clean Data from Docker:

```bash
make docker-clean
```

## ğŸ›  Inspecting the SQLite Database inside the Docker Container
To inspect the SQLite database that runs inside the container, a utility Make command is provided:
```bash
make docker-inspect-db
```
This will:

1. Launch an interactive bash shell inside the data-migration-api container.

2. Open the app.db SQLite file using the sqlite3 command-line interface.
### ğŸ“Œ Requirements:
- The container must be running.
---

## âœ… API Endpoints Summary

Visit the Swagger UI for testing endpoints:
[http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ” Security Considerations

- Codebase scoped to internal POC use
- Run inside Docker to prevent local pollution
- No public endpoints without container isolation

---

## ğŸ“„ License

This project is provided for demonstration purposes only.
