# Data Migration with PySpark and MongoDB

Este mÃ³dulo es una soluciÃ³n de procesamiento ETL desarrollada con **PySpark** y **MongoDB** como alternativa al sistema basado en SQLite. EstÃ¡ optimizada para ser escalable, robusta y fÃ¡cilmente mantenible, cumpliendo los requisitos de un desafÃ­o tÃ©cnico.

## ğŸ“ Estructura del Proyecto

```
data_migration_spark_mongo/
â”‚
â”œâ”€â”€ config/                  # ConfiguraciÃ³n general (SparkSession, Logger)
â”‚   â”œâ”€â”€ logger_config.py     # ConfiguraciÃ³n del sistema de logging
â”‚   â””â”€â”€ spark_config.py      # InicializaciÃ³n del SparkSession
â”‚
â”‚
â”œâ”€â”€ etl/                     # MÃ³dulos ETL independientes
â”‚   â”œâ”€â”€ load_departments.py
â”‚   â”œâ”€â”€ load_jobs.py
â”‚   â”œâ”€â”€ load_hired_employees.py
â”‚   â”œâ”€â”€ run_etl.py           # Orquestador principal
â”‚   â”œâ”€â”€ backup_avro.py       # Respaldo en formato Avro
â”‚   â””â”€â”€ restore_from_backup.py # RestauraciÃ³n desde el Ãºltimo backup
â”‚
â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ validations.py       # Validaciones y limpieza de datos
â”‚
â”œâ”€â”€ backups/                 # Respaldos generados (nombre_fecha-hora.avro)
â”‚
â””â”€â”€ api/                     # FastAPI para inserciÃ³n de datos
    â””â”€â”€ main.py              # Servidor FastAPI corriendo en puerto 8005
```

## ğŸ› ï¸ Requisitos

- Python 3.10+
- PySpark 3.5.1
- MongoDB local corriendo en `localhost:27017`
- Paquetes de Python: ver `requirements.txt`

## â–¶ï¸ EjecuciÃ³n

### Activar entorno virtual

```bash
source venv-optimized/bin/activate
pip install -r requirements.txt
```

### Correr ETL completo

```bash
python3 -m etl.run_etl
```

### Crear respaldo (formato Avro)

```bash
python3 -m etl.backup_avro
```

### Restaurar desde Ãºltimo backup

```bash
python3 -m etl.restore_from_backup
```

## ğŸŒ API (FastAPI)

El servidor corre en `http://localhost:8005` y expone endpoints para insertar datos:

- `POST /departments/` â€” Inserta un solo departamento
- `POST /departments/batch/` â€” Inserta hasta 1000 en batch
- `POST /jobs/`
- `POST /jobs/batch/`
- `POST /hired_employees/`
- `POST /hired_employees/batch/`

## ğŸ“¦ Ejemplo de inserciÃ³n vÃ­a API

```bash
curl -X POST http://localhost:8005/departments/ \
     -H "Content-Type: application/json" \
     -d '{"id": 101, "department": "Data Engineering"}'
```

## ğŸ§ª Validaciones

- ValidaciÃ³n de esquema (tipos y columnas esperadas)
- VerificaciÃ³n de claves forÃ¡neas (en empleados)
- ValidaciÃ³n de formato de fecha ISO en `hired_employees`
- Registro de logs para cada inserciÃ³n con detalles

---

ğŸ—‚ï¸ Proyecto orientado a demostrar capacidades de ingestiÃ³n robusta, validaciÃ³n y persistencia de datos con herramientas modernas.

